{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = np.load('X_train.npy'), np.load('y_train.npy')\n",
    "Z = np.load('X_test.npy')\n",
    "\n",
    "samples, features = X.shape\n",
    "tests = Z.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Support Vector Machine (Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svmTrain(data, labels, cost, kernel, gamma, degree):\n",
    "    model = SVC(C = cost, kernel = kernel, degree = degree, gamma = gamma).fit(data, labels)\n",
    "    vectors = model.n_support_\n",
    "    return (model, sum(vectors))\n",
    "\n",
    "def svmPredict(data, svmModel):\n",
    "    return svmModel.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "PARAMETERS:\n",
    "cost    Penalty parameter C of the error term.\n",
    "\n",
    "kernel  Specifies the kernel type to be used in the algorithm. It must be one of 'linear', 'poly',\n",
    "        'rbf', 'sigmoid', 'precomputed' or a callable. If none is given, 'rbf' will be used.\n",
    "        \n",
    "gamma   Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
    "\n",
    "degree  Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n",
    "'''\n",
    "\n",
    "costs = [10**p for p in range(-2, 3)]\n",
    "kernels = ['linear',\n",
    "           # 'rbf',\n",
    "           'poly']\n",
    "gammas = [10**p for p in range(-4, 1)]\n",
    "degrees = list(range(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileName = 'hw3-lfw-svm-models-labels.txt'\n",
    "\n",
    "def isLinear(kernel): return kernel == 'linear'\n",
    "def isPoly(kernel): return kernel == 'poly'\n",
    "\n",
    "def testAll(costs = [1], kernels = ['linear'], gammas = ['auto'], degrees = [1]):\n",
    "    f = open(fileName, 'w')\n",
    "    # f.write(\"Rows:\\t%d,\\tColumns:\\t%d\\n\" % (samples, features))\n",
    "    f.write(\"['SVM'\") # for eval\n",
    "    for K in kernels:\n",
    "        for C in costs:   \n",
    "            if isLinear(K):\n",
    "                testOne(C, K) # LINEAR\n",
    "            else:\n",
    "                for G in gammas:\n",
    "                    if isPoly(K):\n",
    "                        for D in degrees:\n",
    "                            testOne(C, K, G, D) # POLY\n",
    "                    else:\n",
    "                        testOne(C, K, G) # RBF\n",
    "    f.write(\"]\") # for eval\n",
    "    f.close()\n",
    "                \n",
    "def testOne(cost = 1, kernel = 'linear', gamma = 'auto', degree = 1):\n",
    "    svmModel, totalSV = svmTrain(X, y, cost, kernel, gamma, degree)\n",
    "    a = svmPredict(Z, svmModel).tolist()\n",
    "    '''\n",
    "    f.write(\"Cost:\\t%s\\nKernel:\\t%s\\n\" % (str(cost), str(kernel))) # LINEAR, POLY, RBF\n",
    "    if not isLinear(kernel):\n",
    "        f.write(\"Gamma:\\t%s\\n\" % str(gamma)) # POLY, RBF\n",
    "        if isPoly(kernel):\n",
    "            f.write(\"Degree: %s\\n\" % str(degree)) # POLY\n",
    "    f.write(\"Number of Support Vectors:\\t%s\\n\" % str(totalSV))\n",
    "    f.write(\"Labels:\\t%s\\n\" % str(a))\n",
    "    f.write(\"\\n\")\n",
    "    '''\n",
    "    f.write(\", %s\" % str(a)) # for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testAll(costs, kernels, gammas, degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileName = 'hw3-lfw-svm-models-labels-average.'\n",
    "\n",
    "def getAverage():\n",
    "    with open(fileName + 'txt', 'r') as f:\n",
    "        labels = []\n",
    "        models = eval(f.read())[1:]\n",
    "    f.close()\n",
    "    numModels = len(models)\n",
    "    for row in range(tests):\n",
    "        y = (model[row] for model in models)\n",
    "        counter = Counter(list(y))\n",
    "        mode = counter.most_common()[0][0]\n",
    "        labels.append(mode)\n",
    "    g = open(labelListFileName, 'w')\n",
    "    g.write(str(labels))\n",
    "    g.close()\n",
    "    \n",
    "def toCsv():\n",
    "    f = open(fileName + 'csv', 'w')\n",
    "    f.write('ImageId,PredictedClass\\n')\n",
    "    with open(labelListFileName, 'r') as g:\n",
    "        array = eval(g.read())\n",
    "        i = 0\n",
    "        for prediction in array:\n",
    "            f.write('%d,%d\\n' %(i, prediction))\n",
    "            i += 1\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getAverage(fileName)\n",
    "toCsv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nnTrain(data, labels, solver, alpha, learningRateInit, learningRateType):\n",
    "    model = MLPClassifier(solver = solver, alpha = alpha,\n",
    "                          learning_rate_init = learningRateInit, \\\n",
    "                          learning_rate = learningRateType).fit(data, labels)\n",
    "    return model\n",
    "\n",
    "def nnPredict(data, nnModel):\n",
    "    return nnModel.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "PARAMETERS:\n",
    "solver              {'lbfgs' , 'sgd', 'adam'}, default 'adam'\n",
    "                    'lbfgs' optimizer in the family of quasi-Newton methods\n",
    "                    'adam'  stochastic gradient-based optimizer)\n",
    "                    The solver for weight optimization.\n",
    "                    \n",
    "alpha               float, optional, default 0.0001\n",
    "                    L2 penalty (regularization term) parameter.\n",
    "                    \n",
    "learning_rate       {'constant', 'invscaling', 'adaptive'}, default 'constant'\n",
    "                    'adaptive'  Keeps the learning rate constant to 'learning_rate_init' (below) as long as\n",
    "                    1. training loss keeps decreasing by 'tol' (tolerance), and\n",
    "                    2. 'early_stopping' = True and validation score keeps increasing by 'tol'\n",
    "                    Otherwise, the current learning rate is divided by 5\n",
    "                    # Only for solver = 'sgd'.\n",
    "\n",
    "learning_rate_init  double, optional, default 0.001\n",
    "                    The initial learning rate used. It controls the step-size in updating the weights.\n",
    "                    # Not for solver = 'lbfgs'.\n",
    "\n",
    "early_stopping      Automatically sets aside 10% of training data as validation \n",
    "                    And terminates training when validation score is not improving\n",
    "                    by at least tol for two consecutive epochs.\n",
    "                    # Not for solver = 'lbfgs'.\n",
    "'''\n",
    "\n",
    "solvers = [# 'lbfgs', 'sgd',\n",
    "           'adam']\n",
    "'''\n",
    "alphas = [10**p for p in range(-4, -1)] # 1)]\n",
    "learningRateInits = [0.0001, 0.001] # 10**(-4) and 10**(-3)\n",
    "'''\n",
    "alphas = [0.01]\n",
    "learningRateInits = [0.001]\n",
    "learningRateTypes = ['constant', 'invscaling', 'adaptive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName = 'hw3-lfw-nn.txt'\n",
    "\n",
    "def isLbfgs(solver): return solver == 'lbfgs'\n",
    "def isSgd(solver): return solver == 'sgd'\n",
    "\n",
    "def testAll(solvers = ['lbfgs'], alphas = [0.0001], learningRateInits = [0.001], learningRateTypes = ['constant']):\n",
    "    f = open(fileName, 'w')\n",
    "    # f.write(\"Rows:\\t%d,\\tColumns:\\t%d\\n\" % (samples, features))\n",
    "    for solver in solvers:\n",
    "        for alpha in alphas:\n",
    "            if isLbfgs(solver):\n",
    "                testOne(solver, alpha) # LBFGS\n",
    "            else:\n",
    "                for learnRate in learningRateInits:\n",
    "                    if isSgd(solver):\n",
    "                        for learnType in learningRateTypes:\n",
    "                            testOne(solver, alpha, learnRate, learnType) # SGD\n",
    "                    else:\n",
    "                        testOne(solver, alpha, learnRate) # ADAM\n",
    "    f.close()\n",
    "                \n",
    "def testOne(solver = 'lbfgs', alpha = 0.0001, learningRateInit = 0.001, learningRateType = 'constant'):\n",
    "    nnModel = nnTrain(X, y, solver, alpha, learningRateInit, learningRateType)\n",
    "    a = nnPredict(Z, nnModel).tolist()\n",
    "    '''\n",
    "    f.write(\"Solver:\\t%s\\nAlpha:\\t%s\\n\" % (str(solver), str(alpha))) # LBFGS, SGD, ADAM\n",
    "    if not isLbfgs(solver):\n",
    "        f.write(\"Learning Rate:\\t%s\\n\" % str(learningRateInit))\n",
    "        if isSgd(solver):\n",
    "            f.write(\"Learning Rate Type:\\t%s\\n\" % str(learningRateType))\n",
    "    f.write(\"Labels:\\t%s\\n\" % str(a))\n",
    "    f.write(\"\\n\")\n",
    "    '''\n",
    "    g = open('hw3-lfw-nn-labels.csv', 'w')\n",
    "    g.write('ImageId,PredictedClass\\n')\n",
    "    i = 0\n",
    "    for label in a:\n",
    "        g.write(\"%d,%d\\n\" %(i, label))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testAll(solvers, alphas, learningRateInits, learningRateTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dimensionality reduction: Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "'''\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "PARAMETERS:\n",
    "estimator   A supervised learning estimator with a fit method.\n",
    "step        If greater than or equal to 1, then step corresponds to the (integer) number of features to remove\n",
    "            at each iteration. If within (0.0, 1.0), then step corresponds to the percentage (rounded down) of\n",
    "            features to remove at each iteration.\n",
    "cv          Determines the cross-validation splitting strategy.\n",
    "'''\n",
    "\n",
    "kernel = 'linear'\n",
    "step = 1\n",
    "folds = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = SVC(kernel = kernel)\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "# The \"accuracy\" scoring is proportional to the number of correct classifications.\n",
    "rfecv = RFECV(estimator = svc, step = step, cv = StratifiedKFold(folds), scoring = 'accuracy')\n",
    "X, y = X.tolist(), y.tolist()\n",
    "rfecv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rfecv.get_support(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Build a classification task using 3 informative features\n",
    "'''\n",
    "X, y = make_classification(n_samples=1000, n_features=25, n_informative=3,\n",
    "                           n_redundant=2, n_repeated=0, n_classes=8,\n",
    "                           n_clusters_per_class=1, random_state=0)\n",
    "'''\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "svc = SVC(kernel=\"linear\")\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
