{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework #3 - Labeled Faces in the Wild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriculation Numbers: A0124772E, A0136070R, A0121299A\n",
    "\n",
    "Email Addresses: a0124772@u.nus.edu, e0005572@u.nus.edu, e0008742@u.nus.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################\n",
    "##### IMPORTS #####\n",
    "###################\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# SciKit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "##### MODEL SELECTION FRAMEWORK #####\n",
    "#####################################\n",
    "\n",
    "class ValidatedModel():\n",
    "    def __init__(self):\n",
    "        self.X              = None    # original points\n",
    "        self.y              = None    # original classifications\n",
    "        self.trained_models = None\n",
    "        \n",
    "    \n",
    "    def supplyDataset(self, all_samples, all_labels):\n",
    "        '''\n",
    "            Ensures there are as many labels as samples.\n",
    "            \n",
    "            Sets the training samples X.\n",
    "            Sets the training labels y.\n",
    "        '''\n",
    "        assert all_samples.shape[0] == all_labels.shape[0]\n",
    "        \n",
    "        self.X = all_samples\n",
    "        self.y = all_labels\n",
    "    \n",
    "    def trainAll(self, cross_validation_param=5):\n",
    "        '''\n",
    "            For each split of training and test sets (using k-fold),\n",
    "                * train the model on the training set\n",
    "                * compute E_in\n",
    "                * compute E_out\n",
    "            Store a list of the (model, E_in, E_out) tuples.\n",
    "        '''\n",
    "        self.preprocess()\n",
    "        \n",
    "        kf = KFold(n_splits=cross_validation_param)\n",
    "        self.trained_models = []\n",
    "        \n",
    "        for train_idx, test_idx in kf.split(self.X):\n",
    "            trained_model = self.train(self.X[train_idx], self.y[train_idx])\n",
    "            \n",
    "            E_in  = self.getError(trained_model, self.X[train_idx], self.y[train_idx])\n",
    "            E_out = self.getError(trained_model, self.X[test_idx], self.y[test_idx])\n",
    "            \n",
    "            self.trained_models.append((trained_model, E_in, E_out))\n",
    "        \n",
    "        self.postprocess()\n",
    "    \n",
    "    def getErrors(self):\n",
    "        '''\n",
    "            Computes the average generalisation error (|E_out - E_in|) over all pair of training and test sets.\n",
    "            Returns a pair of the average generalisation error and the average in-sample error.\n",
    "        '''\n",
    "        sum_generalisation_error = 0\n",
    "        sum_E_in = 0\n",
    "        \n",
    "        for model in self.trained_models:\n",
    "            E_in  = model[1]\n",
    "            E_out = model[2]\n",
    "            \n",
    "            sum_generalisation_error += abs(E_in - E_out)\n",
    "            sum_E_in                 += E_in\n",
    "        \n",
    "        average_generalisation_error = sum_generalisation_error / len(self.trained_models)\n",
    "        average_E_in                 = sum_E_in                 / len(self.trained_models)\n",
    "        \n",
    "        return (average_generalisation_error, average_E_in)\n",
    "    \n",
    "    def getError(self, classifier, points, classifications):\n",
    "        '''\n",
    "            Calculate the error of a model over a label given a sample dataset and labels for it.\n",
    "            0/1-loss is used as this is a classification problem.\n",
    "        '''\n",
    "\n",
    "        # use the model to predict the classifications of all points in the test set\n",
    "        predicted_classifications = classifier.predict(points)\n",
    "\n",
    "        # calculate the error using 0/1 loss\n",
    "        N = predicted_classifications.shape[0]\n",
    "        assert N == classifications.shape[0]\n",
    "        num_misclassifications = 0\n",
    "        for i in range(0, N):\n",
    "            if predicted_classifications[i] != classifications[i]:\n",
    "                num_misclassifications += 1\n",
    "\n",
    "        return num_misclassifications/N\n",
    "    \n",
    "    def predict(self, points):\n",
    "        '''\n",
    "            Get the modal prediction across all the models.\n",
    "        '''\n",
    "        num_points = points.shape[0]\n",
    "        predictions_by_model = [] # ith element is prediction of all points by model i\n",
    "        predictions_by_point = [] # ith element is modal prediction of point i by all models\n",
    "        \n",
    "        for model, E_in, E_out in self.trained_models:\n",
    "            predictions_by_model.append(model.predict(points))\n",
    "        \n",
    "        predictions_by_model = np.array(predictions_by_model)\n",
    "        \n",
    "        for i in range(0, num_points):\n",
    "            point_i_modal_prediction = np.argmax(np.bincount(predictions_by_model[:, i]))\n",
    "            predictions_by_point.append(point_i_modal_prediction)\n",
    "            \n",
    "        predictions_by_point = np.array(predictions_by_point)\n",
    "        \n",
    "        return predictions_by_point\n",
    "    \n",
    "    def preprocess(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, points, classifications):\n",
    "        pass\n",
    "    \n",
    "    def postprocess(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CrappySVM(ValidatedModel):\n",
    "    def train(self, samples, labels):\n",
    "        clf = SVC(kernel='linear')\n",
    "        clf.fit(samples, labels)\n",
    "        return clf\n",
    "\n",
    "X = np.load('X_train.npy')\n",
    "y = np.load('y_train.npy')\n",
    "\n",
    "X_train = X[0:400]\n",
    "y_train = y[0:400]\n",
    "\n",
    "example = CrappySVM()\n",
    "\n",
    "example.supplyDataset(X_train, y_train)\n",
    "example.trainAll()\n",
    "\n",
    "print(example.getErrors())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statement of (Team-Level) Individual Work\n",
    "\n",
    "Please initial (between the square brackets) one of the following statements.\n",
    "\n",
    "[X] I, A0124772E and A0136070R and A0121299A, certify that we have followed the CS 3244 Machine Learning class guidelines for homework assignments.  In particular, we expressly vow that we have followed the Facebook rule in discussing with others (out of our team) in doing the assignment and did not take notes (digital or printed) from the discussions.  \n",
    "\n",
    "[ ] I, <*substitute your matric number here*>, did not follow the class rules regarding the homework assignment, because of the following reason:\n",
    "\n",
    "<*Please fill in*>\n",
    "\n",
    "I suggest that I should be graded as follows:\n",
    "\n",
    "<*Please fill in*>\n",
    "\n",
    "### References\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
